{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 (Machine Learning)\n",
    "> This assignment is solved by:-\n",
    "* Name: Vishal Sehgal\n",
    "* Group: CO11\n",
    "* Roll Number: 102003265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.0001, 0.001, 0.01, 0.1, 1, 10, 20, 50]\n",
    "lambdas = [10e-15, 10e-10, 10e-5, 10e-3, 0, 1, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>x_13</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.047198</td>\n",
       "      <td>0.940533</td>\n",
       "      <td>1.096623</td>\n",
       "      <td>1.148381</td>\n",
       "      <td>1.202581</td>\n",
       "      <td>1.259340</td>\n",
       "      <td>1.318778</td>\n",
       "      <td>1.381021</td>\n",
       "      <td>1.446202</td>\n",
       "      <td>1.514459</td>\n",
       "      <td>1.585938</td>\n",
       "      <td>1.660790</td>\n",
       "      <td>1.739176</td>\n",
       "      <td>1.821260</td>\n",
       "      <td>1.907219</td>\n",
       "      <td>1.997235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.117011</td>\n",
       "      <td>0.878054</td>\n",
       "      <td>1.247713</td>\n",
       "      <td>1.393709</td>\n",
       "      <td>1.556788</td>\n",
       "      <td>1.738948</td>\n",
       "      <td>1.942424</td>\n",
       "      <td>2.169709</td>\n",
       "      <td>2.423588</td>\n",
       "      <td>2.707173</td>\n",
       "      <td>3.023942</td>\n",
       "      <td>3.377775</td>\n",
       "      <td>3.773011</td>\n",
       "      <td>4.214494</td>\n",
       "      <td>4.707635</td>\n",
       "      <td>5.258479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.186824</td>\n",
       "      <td>1.024337</td>\n",
       "      <td>1.408551</td>\n",
       "      <td>1.671702</td>\n",
       "      <td>1.984016</td>\n",
       "      <td>2.354677</td>\n",
       "      <td>2.794587</td>\n",
       "      <td>3.316683</td>\n",
       "      <td>3.936319</td>\n",
       "      <td>4.671717</td>\n",
       "      <td>5.544505</td>\n",
       "      <td>6.580351</td>\n",
       "      <td>7.809718</td>\n",
       "      <td>9.268760</td>\n",
       "      <td>11.000386</td>\n",
       "      <td>13.055521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.256637</td>\n",
       "      <td>1.179511</td>\n",
       "      <td>1.579137</td>\n",
       "      <td>1.984402</td>\n",
       "      <td>2.493673</td>\n",
       "      <td>3.133642</td>\n",
       "      <td>3.937850</td>\n",
       "      <td>4.948448</td>\n",
       "      <td>6.218404</td>\n",
       "      <td>7.814277</td>\n",
       "      <td>9.819710</td>\n",
       "      <td>12.339811</td>\n",
       "      <td>15.506664</td>\n",
       "      <td>19.486248</td>\n",
       "      <td>24.487142</td>\n",
       "      <td>30.771450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.326450</td>\n",
       "      <td>0.935173</td>\n",
       "      <td>1.759470</td>\n",
       "      <td>2.333850</td>\n",
       "      <td>3.095735</td>\n",
       "      <td>4.106339</td>\n",
       "      <td>5.446854</td>\n",
       "      <td>7.224981</td>\n",
       "      <td>9.583578</td>\n",
       "      <td>12.712139</td>\n",
       "      <td>16.862020</td>\n",
       "      <td>22.366630</td>\n",
       "      <td>29.668222</td>\n",
       "      <td>39.353420</td>\n",
       "      <td>52.200353</td>\n",
       "      <td>69.241170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y       x_2       x_3       x_4       x_5       x_6  \\\n",
       "0  1.047198  0.940533  1.096623  1.148381  1.202581  1.259340  1.318778   \n",
       "1  1.117011  0.878054  1.247713  1.393709  1.556788  1.738948  1.942424   \n",
       "2  1.186824  1.024337  1.408551  1.671702  1.984016  2.354677  2.794587   \n",
       "3  1.256637  1.179511  1.579137  1.984402  2.493673  3.133642  3.937850   \n",
       "4  1.326450  0.935173  1.759470  2.333850  3.095735  4.106339  5.446854   \n",
       "\n",
       "        x_7       x_8        x_9       x_10       x_11       x_12       x_13  \\\n",
       "0  1.381021  1.446202   1.514459   1.585938   1.660790   1.739176   1.821260   \n",
       "1  2.169709  2.423588   2.707173   3.023942   3.377775   3.773011   4.214494   \n",
       "2  3.316683  3.936319   4.671717   5.544505   6.580351   7.809718   9.268760   \n",
       "3  4.948448  6.218404   7.814277   9.819710  12.339811  15.506664  19.486248   \n",
       "4  7.224981  9.583578  12.712139  16.862020  22.366630  29.668222  39.353420   \n",
       "\n",
       "        x_14       x_15  \n",
       "0   1.907219   1.997235  \n",
       "1   4.707635   5.258479  \n",
       "2  11.000386  13.055521  \n",
       "3  24.487142  30.771450  \n",
       "4  52.200353  69.241170  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([i*np.pi/180 for i in range(60,300,4)])\n",
    "np.random.seed(42)\n",
    "y = np.sin(x) + np.random.normal(0,0.15,len(x))\n",
    "df= pd.DataFrame(np.column_stack([x,y]),columns=['x','y'])\n",
    "for i in range(2,16):\n",
    "    colname = 'x_%d'%i \n",
    "    df[colname] = df['x']**i\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('y', axis=1)\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = 1\n",
    "beta *=2\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_mat = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 16)\n"
     ]
    }
   ],
   "source": [
    "for z in range(len(learning_rates)):\n",
    "    n = len(X_train)\n",
    "    number_of_iterations = 100\n",
    "    lam = lambdas[z]\n",
    "    lr = learning_rates[z]\n",
    "    beta0 = 0\n",
    "    beta = np.zeros(X_train.shape[1])\n",
    "    for itr in range(number_of_iterations):\n",
    "        h = beta0*((1-(lr*lam)/n))\n",
    "        s = 0\n",
    "        d = lr/n\n",
    "        for i in range(n):\n",
    "            s += (beta0 - y_train[i])\n",
    "            for l in range(1, X_train.shape[1]):\n",
    "                s += (beta[l] * X_train[i,l])\n",
    "        beta0 = h - d * s\n",
    "        for j in range(len(beta)):\n",
    "            h = beta[j] * (1-(lr*lam)/n)\n",
    "            s = 0\n",
    "            d = lr/n\n",
    "            for i in range(n):\n",
    "                s += (beta0 - y_train[i])\n",
    "                for l in range(1, X_train.shape[1]):\n",
    "                    s += (beta[l] * X_train[i, l])\n",
    "                s *= X_train[i, j]\n",
    "            beta[j] -= h - d * s\n",
    "    if(z==0):\n",
    "        beta_mat = np.concatenate((np.array(beta0).flatten(), beta))\n",
    "    else:\n",
    "        beta_mat = np.vstack((beta_mat, np.concatenate((np.array(beta0).flatten(), beta))))\n",
    "print(beta_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.insert(X_test, 0, values=1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.7034199 , -1.31365751, -1.05867178, -0.89285793,\n",
       "        -0.78079937, -0.70090067, -0.64095326, -0.59404209, -0.55609958,\n",
       "        -0.5246104 , -0.49793988, -0.47497778, -0.4549412 , -0.43726044,\n",
       "        -0.42150985],\n",
       "       [ 1.        , -1.41470466, -1.20179794, -1.01943343, -0.88000177,\n",
       "        -0.77677941, -0.69968398, -0.64059349, -0.5939375 , -0.55606956,\n",
       "        -0.52460186, -0.49793748, -0.47497711, -0.45494101, -0.43726039,\n",
       "        -0.42150983],\n",
       "       [ 1.        ,  0.37532981,  0.20507588,  0.03810149, -0.10361316,\n",
       "        -0.21375802, -0.29421733, -0.34991708, -0.38627104, -0.40813393,\n",
       "        -0.41948187, -0.42340906, -0.42224425, -0.41769754, -0.41099977,\n",
       "        -0.40302083],\n",
       "       [ 1.        ,  0.89501723,  0.84363424,  0.74523163,  0.62453597,\n",
       "         0.49873713,  0.37784238,  0.26701503,  0.16847807,  0.08274625,\n",
       "         0.00937944, -0.0525624 , -0.10424588, -0.14690173, -0.18173111,\n",
       "        -0.20985424],\n",
       "       [ 1.        , -0.95276028, -0.95634608, -0.90106513, -0.82656059,\n",
       "        -0.75370289, -0.69001949, -0.636632  , -0.59233854, -0.55543143,\n",
       "        -0.52434933, -0.49783818, -0.47493826, -0.45492587, -0.4372545 ,\n",
       "        -0.42150755],\n",
       "       [ 1.        ,  1.41470466,  1.58574261,  1.69975423,  1.7655305 ,\n",
       "         1.79407054,  1.79464345,  1.77435245,  1.73854848,  1.69128716,\n",
       "         1.63567788,  1.57413086,  1.50853075,  1.44036024,  1.37078992,\n",
       "         1.30074489],\n",
       "       [ 1.        ,  0.20210067,  0.01523421, -0.14904633, -0.2748466 ,\n",
       "        -0.36236177, -0.41830902, -0.4505823 , -0.46612212, -0.47035726,\n",
       "        -0.46727413, -0.45968235, -0.4495013 , -0.43800656, -0.42602214,\n",
       "        -0.41406288],\n",
       "       [ 1.        ,  1.06824638,  1.07949814,  1.03408524,  0.95282623,\n",
       "         0.85259504,  0.74480778,  0.63667187,  0.53255303,  0.43496133,\n",
       "         0.3452031 ,  0.26380683,  0.19080348,  0.12591316,  0.06867016,\n",
       "         0.01850696],\n",
       "       [ 1.        , -1.01050333, -0.99150194, -0.92031525, -0.83634185,\n",
       "        -0.75841601, -0.69220428, -0.63761567, -0.59277152, -0.55561861,\n",
       "        -0.52442908, -0.49787175, -0.47495224, -0.45493165, -0.43725687,\n",
       "        -0.42150852],\n",
       "       [ 1.        ,  1.5879338 ,  1.85612317,  2.07931841,  2.2599986 ,\n",
       "         2.40495844,  2.52073198,  2.61260445,  2.68469343,  2.74021473,\n",
       "         2.78171659,  2.81125276,  2.83050533,  2.84087183,  2.84352781,\n",
       "         2.83947269],\n",
       "       [ 1.        ,  0.95276028,  0.92097715,  0.83839407,  0.72865951,\n",
       "         0.60908694,  0.49034005,  0.37839755,  0.27628165,  0.18521673,\n",
       "         0.1053582 ,  0.03624636, -0.02291059, -0.07306028, -0.11519736,\n",
       "        -0.15029806],\n",
       "       [ 1.        ,  1.18373247,  1.24313272,  1.24260417,  1.19938987,\n",
       "         1.129068  ,  1.04303754,  0.94911877,  0.85256742,  0.75687365,\n",
       "         0.66431413,  0.57632526,  0.49375781,  0.4170533 ,  0.3463681 ,\n",
       "         0.28166184],\n",
       "       [ 1.        ,  0.08661457, -0.10493493, -0.26150979, -0.37251931,\n",
       "        -0.44280791, -0.48205342, -0.49964324, -0.50303922, -0.49764227,\n",
       "        -0.48714819, -0.47398474, -0.45969022, -0.44520271, -0.43106699,\n",
       "        -0.4175768 ],\n",
       "       [ 1.        , -1.53019075, -1.25037695, -1.03782667, -0.88646941,\n",
       "        -0.77893783, -0.7003775 , -0.64081009, -0.5940037 , -0.55608944,\n",
       "        -0.52460775, -0.4979392 , -0.47497761, -0.45494116, -0.43726043,\n",
       "        -0.42150984],\n",
       "       [ 1.        ,  1.29921857,  1.41188087,  1.46435809,  1.4697948 ,\n",
       "         1.44174493,  1.39085365,  1.32489419,  1.24946001,  1.16858261,\n",
       "         1.085178  ,  1.00135619,  0.91863658,  0.83810055,  0.76050145,\n",
       "         0.68634552],\n",
       "       [ 1.        , -0.72178809, -0.80293866, -0.80930254, -0.77555676,\n",
       "        -0.72678254, -0.67633183, -0.62986347, -0.58906203, -0.5538716 ,\n",
       "        -0.5236166 , -0.49749769, -0.47478145, -0.45485419, -0.43722194,\n",
       "        -0.42149284],\n",
       "       [ 1.        , -1.24147552, -1.11934145, -0.98408074, -0.86591542,\n",
       "        -0.77144882, -0.69774049, -0.63990426, -0.5936982 , -0.55598784,\n",
       "        -0.52457432, -0.49792829, -0.47497407, -0.45494002, -0.43726006,\n",
       "        -0.42150973],\n",
       "       [ 1.        , -1.35696161, -1.17559084, -1.00873515, -0.87594881,\n",
       "        -0.77532321, -0.69918059, -0.64042446, -0.59388201, -0.55605167,\n",
       "        -0.52459618, -0.49793569, -0.47497655, -0.45494084, -0.43726033,\n",
       "        -0.42150981]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0007670795701477662\n",
      "-0.0008683635819561886\n",
      "-0.0016467393646784068\n",
      "-0.0001541312417838725\n",
      "0.024529460562747962\n",
      "-3.956670783926992e+192\n",
      "-7.592652731718333e+275\n",
      "-inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-85-0083cc4984c4>:4: RuntimeWarning: overflow encountered in power\n",
      "  square_error=np.power(err,2)\n"
     ]
    }
   ],
   "source": [
    "for beta in beta_mat:\n",
    "    y_pred = X_test.dot(beta)\n",
    "    err = y_test - y_pred\n",
    "    square_error=np.power(err,2)\n",
    "    sum_square_error=np.sum(square_error)\n",
    "    mean_square_error=sum_square_error/len(y_pred)\n",
    "    rms_error=np.sqrt(mean_square_error)\n",
    "    y_mean=np.mean(y_test)\n",
    "    total_variance=np.sum((y_test-y_mean)**2)\n",
    "    print(1-sum_square_error/total_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hence the best value of lambda comes out to be 10e-3 and alpha to be 1 in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
